{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1. Personalize User-Item Interaction Data 준비 및 환경 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import \n",
    "\n",
    "파이썬에는 광범위한 라이브러리 모음이 포함되어 있으며, 본 LAB을 위해서 핵심 Data Scientist용 Tool 인 boto3 (AWS SDK) 및 Pandas/Numpy와 같은 라이브러리를 가져와야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#!pip install jsonlines\n",
    "#from codes import lambda_personalize\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import jsonlines\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdate\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 여러분의 환경이 Amazon Personalize와 성공적으로 통신할 수 있는지 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성할 오브젝트의 끝에 임의의 숫자를 부여하기 위해 suffix 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't need profile, set USER_PROFILE=\"\"\n",
    "PROFILE_NAME=\"CUSTOMER\"\n",
    "\n",
    "\n",
    "WORK_DATE=\"20200716\"\n",
    "WORK_DATE_PATH=\"2020/07/16\"\n",
    "\n",
    "data_dir = \"data\"\n",
    "account_id = \"870180618679\"\n",
    "\n",
    "BUCKET_NAME = \"customer-poc\"\n",
    "KEY_PREFIX=WORK_DATE\n",
    "\n",
    "\n",
    "INTERACTION_FILE=\"interaction.csv\"\n",
    "USER_FILE=\"user_meta.csv\"\n",
    "ITEM_FILE=\"item_meta.csv\"\n",
    "\n",
    "DATA_BUCKET_NAME = \"customer-poc\"\n",
    "bucket=DATA_BUCKET_NAME \n",
    "PREFIX='hrnn-meta'\n",
    "#bucket_name = DATA_BUCKET_NAME\n",
    "ROLE_NAME = \"CUSTOMER-PersonalizeRetailRole-0612\"\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "\n",
    "DATA_SET_GROUP_NAME= WORK_DATE+ \"-dataset-group-\"+suffix\n",
    "#SCHEMA_NAME_INTERACTIONS= WORK_DATE+ \"-schema-interactions\"\n",
    "#SCHEMA_NAME_USERS= PREFIX + \"-schema-users\"\n",
    "#SCHEMA_NAME_ITEMS= PREFIX + \"-schema-items\"\n",
    "\n",
    "DATASET_NAME_INTERACTION=\"customer-dataset-interactions\"\n",
    "DATASET_NAME_USERS=\"customer-dataset-users\"\n",
    "DATASET_NAME_ITEMS=\"customer-dataset-items\"\n",
    "\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "\n",
    "BATCH_TARGET_USERS_FILE= \"users_for_batch_\"+ WORK_DATE + \".json\"\n",
    "role_arn=\"arn:aws:iam::870180618679:role/customer-PersonalizeRetailRole-0612\"\n",
    "\n",
    "DATA_PREFIX = \"dataset\"\n",
    "BATCH_PREFIX= \"batch\"\n",
    "\n",
    "LOCAL_CLEAN_DATA_PATH=data_dir+'/'+WORK_DATE+'/'+PREFIX+'/'+DATA_PREFIX \n",
    "S3_DATA_IMPORT_PATH=WORK_DATE+'/'+PREFIX+'/'+DATA_PREFIX \n",
    "\n",
    "S3_BATCH_INPUT_PATH=WORK_DATE+'/'+PREFIX+'/'+BATCH_PREFIX \n",
    "S3_BATCH_OUTPUT_PATH=WORK_DATE+'/'+PREFIX+'/'+BATCH_PREFIX \n",
    "S3_BATCH_OUTPUT_FILE=S3_BATCH_OUTPUT_PATH+'/'+BATCH_TARGET_USERS_FILE+\".out\"\n",
    "LOCAL_BATCH_PATH=data_dir+'/'+WORK_DATE+'/'+PREFIX+'/'+BATCH_PREFIX\n",
    "\n",
    "LOCAL_BATCH_INPUT_FILE=LOCAL_BATCH_PATH+'/'+BATCH_TARGET_USERS_FILE\n",
    "LOCAL_BATCH_OUTPUT_FILE=LOCAL_BATCH_PATH+'/'+BATCH_TARGET_USERS_FILE+\".out\"\n",
    "\n",
    "\n",
    "os.makedirs(LOCAL_CLEAN_DATA_PATH,exist_ok=True)\n",
    "os.makedirs(LOCAL_BATCH_PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Data 다운로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=os.path.join(data_dir,INTERACTION_FILE)\n",
    "\n",
    "df=pd.read_csv(file_name)\n",
    "##########################################################\n",
    "# columns이름 변경 \n",
    "##########################################################\n",
    "df.columns=[\"USER_ID\",\"ITEM_ID\",\"EVENT_TYPE\",\"TIMESTAMP\"]\n",
    "##########################################################\n",
    "df_origin=df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_origin.copy()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL DATA제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# columns 이름 변경 df['OOOOO']\n",
    "##########################################################\n",
    "\n",
    "print(\"# of rows of Null TimeStamp : {}\".format(df['TIMESTAMP'].isnull().sum()))\n",
    "print(\"# of rows of Null Event Type : {}\".format(df['EVENT_TYPE'].isnull().sum()))\n",
    "print(\"# of rows of Null User ID : {}\".format(df['USER_ID'].isnull().sum()))\n",
    "print(\"# of rows of Null Item ID : {}\".format(df['ITEM_ID'].isnull().sum()))\n",
    "#df[df['TIMESTAMP'].isnull()]\n",
    "\n",
    "#########전체 INTERACTION 'null' 확인##########\n",
    "#row_has_NaN = is_NaN.any(axis=1)\n",
    "#rows_with_NaN = df[row_has_NaN]\n",
    "#print(rows_with_NaN)\n",
    "#len(rows_with_NaN)\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 타입 확인 및 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Time stamp 가 표준 양식대로 프린트 되는지 확인 \n",
    "# df.TIMESTAMP / 1000000 (분모값 수정)\n",
    "# 나눠주는 숫자는 input에 따라 다름 \n",
    "##############################################\n",
    "그게에 따라 나눠주는 숫자 변경 필요. \n",
    "arb_time_stamp = df.iloc[50]['TIMESTAMP']/1000000\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TIMESTAMP  = df.TIMESTAMP / 1000000\n",
    "arb_time_stamp = df.iloc[50]['TIMESTAMP']\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"from\",datetime.utcfromtimestamp(df['TIMESTAMP'].min()).strftime('%Y-%m-%d %H:%M:%S'), \"to\", datetime.utcfromtimestamp(df['TIMESTAMP'].max()).strftime('%Y-%m-%d %H:%M:%S') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EVENT_TYPE = df.EVENT_TYPE .astype(str)\n",
    "df.ITEM_ID = df.ITEM_ID.astype(str)\n",
    "df.USER_ID = df.USER_ID.astype(str)\n",
    "df.TIMESTAMP=df.TIMESTAMP.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_unique=pd.DataFrame(item_unique,columns=['ITEM_ID'])\n",
    "#user_unique=pd.DataFrame(user_unique,columns=['USER_ID'])\n",
    "item_unique=df.ITEM_ID.unique()\n",
    "user_unique=df.USER_ID.unique()\n",
    "item_unique=pd.DataFrame(item_unique)\n",
    "user_unique=pd.DataFrame(user_unique)\n",
    "item_unique.to_csv(data_dir+\"/\" +\"unique_item_index.csv\")\n",
    "user_unique.to_csv(data_dir+\"/\" +\"unique_user_index.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  INTERACTION DATA 정보 확인\n",
    "\n",
    "Personalize에서 학습을 수행하기 위해서는 다음과 [official limits](https://docs.aws.amazon.com/personalize/latest/dg/limits.html)같은 데이터 요구사항을 맞추어야 합니다. \n",
    "\n",
    "* 최소 25명 고유 사용자 \n",
    "* 최소 100개 고유 아이템 \n",
    "* 사용자 당 2개 이상의 Interaction(예. 구매,평가 등) 기록\n",
    "\n",
    "\n",
    "하지만 일반적으로 다음과 같은 데이터가 준비 되어 있는것이 좋습니다. \n",
    "\n",
    "* 최소 50명 고유 사용자 \n",
    "* 최소 100개 고유 아이템 \n",
    "* 사용자 당 24 이상의 Interaction(예. 구매,평가 등) 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = df['ITEM_ID'].unique()\n",
    "unique_users = df['USER_ID'].unique()\n",
    "print(\"unique_items: {}, Unique_users : {}\".format(len(unique_items),len(unique_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in category_feature:\n",
    "#    print(\"%s column is processing\" % (col))\n",
    "print(df.EVENT_TYPE.value_counts())\n",
    "df.EVENT_TYPE.value_counts().plot(kind='bar')\n",
    "plt.title(\"EVENT_TYPE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_counts = df.groupby(\"USER_ID\").count().loc[:,[\"EVENT_TYPE\"]].rename(columns={\"EVENT_TYPE\":\"INTERACTION_COUNTS\"})\n",
    "print(user_activity_counts.info())\n",
    "user_activity_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_activity_counts.quantile([.1,.2,.3,.4,.5,.6,.8,.9,.95,.99,.999,.9999,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_counts=user_activity_counts.reset_index()\n",
    "activities = user_activity_counts.groupby('INTERACTION_COUNTS').count()\n",
    "activities.columns=['NUM_USERS']\n",
    "activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(unique_users)==activities['NUM_USERS'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.loc[:,:].plot(kind='bar', figsize=(15,5), ylim=(0,activities.index.max()))\n",
    "plt.title(\"activities users group\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Users with interactions more than 24 interactions: {}\".format(activities[activities.index > 24].NUM_USERS.sum()))\n",
    "print(\"Users with interactions less than & equal 24 interactions: {}\".format(activities[activities.index <= 24].NUM_USERS.sum()))\n",
    "slow_user=user_activity_counts[user_activity_counts['INTERACTION_COUNTS']<=24]\n",
    "print(\"slow_user_percentage:{}\".format(len(slow_user)/len(user_activity_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"USER_ID\").count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아이템 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_long_tails(df, is_in_event_types, groupby_column_name, count_name, range1=10, range2=100, range3=300):\n",
    "    filtered_df = df.loc[df[\"EVENT_TYPE\"].isin(is_in_event_types)]\n",
    "    groupby_df = filtered_df.groupby(groupby_column_name).count().loc[:,[\"EVENT_TYPE\"]].rename(columns={\"EVENT_TYPE\":count_name})\n",
    "    sorted_df = groupby_df.sort_values([count_name], ascending=False)\n",
    "    \n",
    "    sorted_df[:].plot(kind='line', figsize=(15,5))\n",
    "    plt.title(count_name + \" per \" + groupby_column_name)\n",
    "    plt.show()\n",
    "\n",
    "    sorted_df[:range1].plot(kind='line', figsize=(15,5))\n",
    "    plt.title(count_name + \" per \" + groupby_column_name + \"/ 1 ~\" + str(range1) + \"th\")\n",
    "    plt.show()\n",
    "    \n",
    "    sorted_df[range1:range2].plot(kind='line', figsize=(15,5))\n",
    "    plt.title(count_name + \" per \" + groupby_column_name + \" / \" + str(range1) + \"th ~ \"+ str(range2) + \"th\")\n",
    "    plt.show()\n",
    "\n",
    "    sorted_df[range2:range3].plot(kind='line', figsize=(15,5))\n",
    "    plt.title(count_name + \" per \" + groupby_column_name + \" / \" + str(range2) + \"th ~ \"+ str(range3) + \"th\")\n",
    "    plt.show()\n",
    "    \n",
    "    sorted_df[range3:].plot(kind='line', figsize=(15,5))\n",
    "    plt.title(count_name + \" per \" + groupby_column_name + \" / \" + str(range3) + \"th ~ \")\n",
    "    plt.show()\n",
    "    \n",
    "#draw_long_tails(interactions_org, [\"order\"], \"ITEM_ID\", \"ORDERS\", 100, 1000, 3000)\n",
    "draw_long_tails(df, [\"order\",\"click\"], \"ITEM_ID\", \"ORDERS & CLICK\", 10, 100, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Data 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=os.path.join(data_dir,USER_FILE)\n",
    "users=pd.read_csv(file_name)\n",
    "users.columns=['USER_ID','AGE','GENDER']\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.USER_ID = users.USER_ID.astype(str)\n",
    "users.AGE = users.AGE.astype(str)\n",
    "users.GENDER = users.GENDER.astype(str)\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_gender_counts = users.groupby('GENDER').count().loc[:,[\"USER_ID\"]].rename(columns={\"USER_ID\":\"USER_GENDER_COUNTS\"})\n",
    "user_gender_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_gender_counts = users.groupby('AGE').count().loc[:,[\"USER_ID\"]].rename(columns={\"USER_ID\":\"USER_AGE_COUNTS\"})\n",
    "user_gender_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 데이터 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=os.path.join(data_dir,ITEM_FILE)\n",
    "items=pd.read_csv(file_name)\n",
    "items.columns=[\"ITEM_ID\",\"CATEGORY\"]\n",
    "items.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cat_counts = items.groupby('CATEGORY').count().loc[:,[\"ITEM_ID\"]].rename(columns={\"ITEM_ID\":\"CATEGORY_COUNTS\"})\n",
    "item_cat_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of rows of Null ITEM_ID : {}\".format(items['ITEM_ID'].isnull().sum()))\n",
    "print(\"# of rows of Null CATEGORY : {}\".format(items['CATEGORY'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.ITEM_ID = items.ITEM_ID.astype(str)\n",
    "items.CATEGORY = items.CATEGORY.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 S3 업로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload에 몇분 소요 (600MB)\n",
    "\n",
    "interaction_object_key = \"interactions_\" + WORK_DATE + \".csv\"\n",
    "user_object_key=\"users_\"+ WORK_DATE + \".csv\"\n",
    "item_object_key=\"items_\"+WORK_DATE + \".csv\"\n",
    "\n",
    "interaction_file=LOCAL_CLEAN_DATA_PATH+\"/\"+interaction_object_key\n",
    "user_file=LOCAL_CLEAN_DATA_PATH+\"/\"+user_object_key\n",
    "item_file=LOCAL_CLEAN_DATA_PATH+\"/\"+item_object_key\n",
    "\n",
    "df[[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\",\"EVENT_TYPE\"]].to_csv(interaction_file,index=False)\n",
    "users.to_csv(user_file,index=False)\n",
    "items.to_csv(item_file,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DATA_IMPORT_PATH=WORK_DATE+'/'+PREFIX+'/'+DATA_PREFIX \n",
    "\n",
    "target=S3_DATA_IMPORT_PATH+\"/\"+interaction_object_key\n",
    "boto3.Session().resource('s3').Bucket(DATA_BUCKET_NAME).Object(target).upload_file(interaction_file)\n",
    "\n",
    "target=S3_DATA_IMPORT_PATH+\"/\"+user_object_key\n",
    "boto3.Session().resource('s3').Bucket(DATA_BUCKET_NAME).Object(target).upload_file(user_file)\n",
    "\n",
    "\n",
    "target=S3_DATA_IMPORT_PATH+\"/\"+item_object_key\n",
    "boto3.Session().resource('s3').Bucket(DATA_BUCKET_NAME).Object(target).upload_file(item_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(2))\n",
    "print(items.head(2))\n",
    "print(users.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스키마 생성\n",
    "\n",
    "Personalize가 데이터를 이해하는 방법의 핵심 구성 요소는 아래 정의 된 스키마(schema)에서 비롯됩니다. 이 설정은 CSV 파일을 통해 제공된 데이터를 요약하는 방법을 Personalize 서비스에 알려줍니다. 열(column)과 유형(type)은 위에서 만든 파일의 내용과 일치합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction 스키마 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_schema_name=\"Interaction-schema-\"+WORK_DATE+\"-\"+suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "       \n",
    "        \n",
    "        { \n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = interaction_schema_name,\n",
    "    schema = json.dumps(interaction_schema)\n",
    ")\n",
    "\n",
    "interaction_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User 스키마 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_schema_name=\"User-schema-\"+WORK_DATE+\"-\"+suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "      {\n",
    "          \"name\": \"AGE\",\n",
    "          \"type\": \"string\",\n",
    "          \"categorical\": True\n",
    "      },\n",
    "        {\n",
    "          \"name\": \"GENDER\",\n",
    "          \"type\": \"string\",\n",
    "          \"categorical\": True\n",
    "      }\n",
    "     \n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = user_schema_name,\n",
    "    schema = json.dumps(user_schema)\n",
    ")\n",
    "\n",
    "user_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_schema_name=\"Item-schema-\"+WORK_DATE+\"-\"+suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "    {\n",
    "        \"name\": \"ITEM_ID\",\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "   \n",
    "    \n",
    "    {\n",
    "        \"name\": \"CATEGORY\",\n",
    "        \"type\": [\"string\",\"null\"],\n",
    "        \"categorical\": True\n",
    "    }\n",
    "    \n",
    "      \n",
    "        \n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_metadata_schema_response = personalize.create_schema(\n",
    "    name = item_schema_name,\n",
    "    schema = json.dumps(item_schema)\n",
    ")\n",
    "\n",
    "item_schema_arn = create_metadata_schema_response['schemaArn']\n",
    "print(json.dumps(create_metadata_schema_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 세트 그룹 생성 및 대기\n",
    "\n",
    "Personalize에서 가장 큰 단위는 **데이터 세트 그룹(Dataset Group)** 이며, 이렇게 하면 데이터, 이벤트 추적기(event tracker), 솔루션(solution) 및 캠페인(campaign)이 분리됩니다. 공통의 데이터 수집을 공유하는 것들을 그룹화합니다. 원하는 경우 아래 그룹명을 자유롭게 변경해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트 그룹 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = DATA_SET_GROUP_NAME\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 세트 그룹이 활성화 상태가 될 때까지 대기\n",
    "\n",
    "아래의 모든 항목에서 Dataset Group을 사용하려면 활성화(active)가 되어야 합니다. 아래 셀을 실행하고 DatasetGroup: ACTIVE로 변경될 때까지 기다려 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트 생성\n",
    "\n",
    "그룹 다음으로 생성할 것은 실제 데이터 세트입니다. 아래의 코드 셀을 실행하여 데이터 세트을 생성해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = DATASET_NAME_INTERACTION,\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interaction_schema_arn\n",
    ")\n",
    "\n",
    "interaction_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  USER 데이터 세트 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"USERS\"\n",
    "\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = DATASET_NAME_USERS,\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = user_schema_arn\n",
    ")\n",
    "\n",
    "user_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITEM 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"ITEMS\"\n",
    "\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = DATASET_NAME_ITEMS,\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = item_schema_arn\n",
    ")\n",
    "\n",
    "item_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 버킷에 정책 부여\n",
    "\n",
    "Amazon Personalize는 앞서 생성한 S3 버킷의 내용을 읽을 수 있어야 합니다. 아래 코드 셀로 S3 버킷 접근 정책(policy)을 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\",\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=DATA_BUCKET_NAME, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalize IAM Role 생성\n",
    "\n",
    "또한, Amazon Personalize는 특정 작업들을 실행할 권한을 갖기 위해, AWS에서 역할을 맡을 수 있는 기능이 필요합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = ROLE_NAME\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    create_role_response = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "    );\n",
    "\n",
    "    iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "    );\n",
    "\n",
    "    role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        role_arn = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role_name,    \n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess'\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트 Import\n",
    "\n",
    "이전에는 정보를 저장하기 위해 데이터 세트 그룹 및 데이터 세트를 생성했으므로, \n",
    "이제는 모델 구축을 위해 S3에서 Amazon Personalize로 데이터를 로드하는 import job을 실행합니다.\n",
    "\n",
    "#### Interaction 데이터 세트 Import Job 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"customer-interaction-dataset-import-\" + WORK_DATE+\"-\"+suffix,\n",
    "    datasetArn = interaction_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(DATA_BUCKET_NAME, S3_DATA_IMPORT_PATH+\"/\"+interaction_object_key)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "interation_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"customer-users-dataset-import-\" + WORK_DATE+\"-\"+suffix,\n",
    "    datasetArn = user_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(DATA_BUCKET_NAME, S3_DATA_IMPORT_PATH+\"/\"+user_object_key)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "user_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"customer-item-dataset-import-\" + WORK_DATE+\"-\"+suffix,\n",
    "    datasetArn = item_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(DATA_BUCKET_NAME, S3_DATA_IMPORT_PATH+\"/\"+item_object_key)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "item_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store values 세션 끊길거 대비 \n",
    "%store BUCKET_NAME\n",
    "%store DATA_BUCKET_NAME\n",
    "%store dataset_group_arn\n",
    "%store interaction_dataset_arn\n",
    "%store user_dataset_arn\n",
    "%store item_dataset_arn\n",
    "%store interation_dataset_import_job_arn\n",
    "%store user_dataset_import_job_arn\n",
    "%store item_dataset_import_job_arn\n",
    "%store ROLE_NAME\n",
    "%store role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아이템 데이터 세트 Import Job 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트 Import job이 활성화 상태가 될 때까지 대기\n",
    "\n",
    "Import job이 완료되기까지 시간이 걸립니다. 아래 코드 셀의 출력 결과가 DatasetImportJob: ACTIVE가 될 때까지 기다려 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = interation_dataset_import_job_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print(\"DatasetImportJob: {}\".format(status))\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print(\"LatestDatasetImportJobRun: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 솔루션 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Recipe 선택 \n",
    "hrnn_recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn-metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 생성 \n",
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"customer-hrnn-meta-all\" + WORK_DATE,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = hrnn_recipe_arn,\n",
    ")\n",
    "\n",
    "hrnn_meta_solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 솔루션 버전 생성\n",
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = hrnn_meta_solution_arn\n",
    ")\n",
    "\n",
    "hrnn_meta_solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 8*60*60 # 8 hours\n",
    "while time.time() < max_time:\n",
    "      \n",
    "    #hrnn status\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = hrnn_meta_solution_version_arn\n",
    "    )  \n",
    "    status_hrnn_meta = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"HRNN META SolutionVersion: {}\".format(status_hrnn_meta))\n",
    "    \n",
    "    if  (status_hrnn_meta == \"ACTIVE\" or status_hrnn_meta == \"CREATE FAILED\"):\n",
    "        break\n",
    " \n",
    "    time.sleep(300)\n",
    "\n",
    "print(\"All solution creation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store hrnn_meta_solution_version_arn\n",
    "%store hrnn_meta_solution_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 솔루션 평가하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = hrnn_meta_solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_target_users = df.USER_ID.unique()\n",
    "n = 0\n",
    "f = open(LOCAL_BATCH_INPUT_FILE,\"w\")\n",
    "for user in batch_target_users:\n",
    "    f.write(\"{\\\"userId\\\":\\\"%s\\\"}\\n\" % user)\n",
    "    n = n + 1\n",
    "    #for the test\n",
    "    #if n> 100:\n",
    "    #    break\n",
    "    \n",
    "f.close()\n",
    "print(BATCH_TARGET_USERS_FILE)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to S3\n",
    "boto3.Session().resource('s3').Bucket(DATA_BUCKET_NAME).Object(S3_BATCH_INPUT_PATH+\"/\"+BATCH_TARGET_USERS_FILE).upload_file(LOCAL_BATCH_INPUT_FILE)\n",
    "\n",
    "s3_input_path = \"s3://\" + DATA_BUCKET_NAME + \"/\"+S3_BATCH_INPUT_PATH+\"/\"+BATCH_TARGET_USERS_FILE\n",
    "print(s3_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path\n",
    "s3_output_path = \"s3://\" +DATA_BUCKET_NAME +\"/\"+S3_BATCH_OUTPUT_PATH+\"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchInferenceJobArn = personalize.create_batch_inference_job (\n",
    "    solutionVersionArn = hrnn_meta_solution_version_arn,\n",
    "    jobName = \"Customer-Batch-Inference-Job-HRNN-META-\"+WORK_DATE+\"-\"+suffix,\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
    ")\n",
    "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']\n",
    "batchInferenceJobArn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_time = datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"HRNN Meta DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    describe_dataset_inference_job_response = personalize.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "  \n",
    "    if (status == \"ACTIVE\" or status == \"CREATE FAILED\"):\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3.download_file(DATA_BUCKET_NAME,S3_BATCH_OUTPUT_FILE,LOCAL_BATCH_OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_batch_result(filename, key_name):\n",
    "    result = {}\n",
    "    fp = open(filename)\n",
    "    reader = jsonlines.Reader(fp)\n",
    "    count = 0\n",
    "    for record in reader:\n",
    "        result[record[\"input\"][key_name]] = str.join(\",\",record[\"output\"][\"recommendedItems\"])\n",
    "        count += 1\n",
    "    reader.close()\n",
    "    fp.close()\n",
    "    \n",
    "    print(\"Found records:\", count, len(result))\n",
    "    return result\n",
    "\n",
    "def unique_count(result):\n",
    "    recommend_keys = {}\n",
    "    \n",
    "    duplicate_cnt = 0\n",
    "    unique_cnt = 0\n",
    "    for k in result:\n",
    "        key = result[k]\n",
    "        \n",
    "        if key not in recommend_keys:\n",
    "            unique_cnt += 1            \n",
    "            recommend_keys[key] = { \"count\": 1, \"keys\": k }\n",
    "        else:\n",
    "            recommend_keys[key][\"count\"] = recommend_keys[key][\"count\"] + 1\n",
    "            #recommend_keys[key][\"keys\"] = recommend_keys[key][\"keys\"] + \",\" + k\n",
    "            duplicate_cnt += 1\n",
    "        #print(f'dup:%10d, unique:%10d, %s is processing…\\r' % (duplicate_cnt, unique_cnt, k), end=\"\")\n",
    "\n",
    "    return recommend_keys, unique_cnt, duplicate_cnt\n",
    "\n",
    "hrnn_result = read_batch_result(LOCAL_BATCH_OUTPUT_FILE, \"userId\")\n",
    "recommend_keys, unique_cnt, duplicate_cnt = unique_count(hrnn_result)\n",
    "\n",
    "print(f'dup:%10d, unique:%10d\\n' % (duplicate_cnt, unique_cnt))\n",
    "cnt = 10\n",
    "for i in sorted(recommend_keys, key=lambda x: (recommend_keys[x]['count']), reverse=True):\n",
    "    print(recommend_keys[i], i)\n",
    "    if cnt < 0: \n",
    "        break\n",
    "    cnt -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store batchInferenceJobArn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캠페인 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"Customer-hrnn-campaign-\" + WORK_DATE,\n",
    "    solutionVersionArn = hrnn_solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "hrnn_campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "user_id= test_user_id\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = hrnn_campaign_arn,\n",
    "    userId = str(user_id),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_title_list = []\n",
    "recommendation_id_list=[]\n",
    "for item in item_list:\n",
    "    recommendation_title_list.append(title)\n",
    "    recommendation_id_list.append(item['itemId'])\n",
    "recommendations_df = pd.DataFrame(recommendation_title_list, columns = ['OriginalRecs'])\n",
    "recommendations_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store hrnn_campaign_arn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
